## Introduction

We provide a powerful API for interacting with various AI functionalities, including HTTP requests to a server and a Node.js SDK. This documentation covers the usage of both the HTTP API and the Node.js SDK.

## HTTP API

### Base URL
The base URL for the HTTP API is `http://localhost:4333`.

### Endpoints

#### 1. `POST /api/v1/request`

This endpoint is used to handle various AI requests.

##### **Request Structure**
- **Headers:**
  - `Authorization`: API key for authorization.
  
- **Body:**
  - `{}`: `Object` with keys: `type`, `data` where:
    - `type` - request type, must be a `string`, it can take the following values: (`web_search`, `llm_inference`, `visual_imagine`, `visual_upscale`, `visual_vary`, `visual_upsample`, `visual_outpaint`);
    - `data` - request body, depends on `type` parameter.

Example:
```json
{
  "type": "string", // Type of request (e.g., search, llm_inference)
  "data": { // Request-specific data
    // Varies based on type
  }
}
```

##### **Response Structure**
- **Success (200)**:
```json
{
  "status": "1",
  "data": {
    "results": [], // Results from the request
    "extendedResults": [] // Extended results if any
  }
}
```

- **Errors**:
```json
{
  "status": "-1",
  "code": "error_code", // Error code
  "data": {}
}
```

### Service Functions

#### handleSearch
Handles search requests.

##### **Request Example**
```json
{
  "type": "search",
  "data": {
    "query": "example search query"
  }
}
```

#### handleInfer
Handles inference requests.

##### **Request Example**
```json
{
  "type": "llm_inference",
  "data": {
    "model": "claude-sonnet-3.5",
    "messages": [
      {
        "role": "user",
        "content": "Hello, how can I help you?"
      }
    ],
    "web": {
      "results": [],
      "extendedResults": []
    }
  }
}
```

#### handleVisualImagine
Handles image generation requests.

##### **Request Example**
```json
{
  "type": "visual/imagine",
  "data": {
    "prompt": "A beautiful sunrise over the mountains",
    "model": "recraft"
  }
}
```

#### handleVisualUpscale
Handles image upscaling requests.

##### **Request Example**
```json
{
  "type": "visual/upscale",
  "options": {
    "data": "base64_image_data",
    "choice": "1"
  }
}
```

## Node.js SDK

### Installation

To use the Node.js SDK, install it via npm:

```bash
npm install your-sdk-package
```

### Usage

```javascript
const PublicAPIWrapper = require('./wrp/index');

// Initialize the API wrapper
const api = new PublicAPIWrapper('your_api_key');

async function main() {
  try {
    await api.infer({
      model: "claude-sonnet-3.5",
      messages: [
        {
          role: 'user',
          content: 'What is the capital of France?'
        }
      ]
    }).then((stream) => {
      stream.on('data', (chunk) => {
        let inference = JSON.parse(chunk.toString());
        if (inference) {
          if (inference.type === 'completion.data') {
            console.log(inference.data);
          } else if (inference.type === 'completion.end') {
            console.log('Stream completed.');
          } else if (inference.type === 'completion.error') {
            console.error('Error:', inference.data);
          }
        }
      });
    });
  } catch (error) {
    console.error('An error occurred:', error);
  }
}

main();
```

### API Methods

#### `infer(RequestBody)`
- **Description**: Sends a request for inference.
- **Parameters**: `RequestBody` - Object containing messages and model information.

#### `imagine(options)`
- **Description**: Generates images based on the provided prompt.
- **Parameters**: `options` - Object containing the prompt and model.

#### `visualUpscale(options)`
- **Description**: Upscales a given image.
- **Parameters**: `options` - Object containing image data and choices for upscaling.

### Conclusion

For more information and detailed examples, refer to the specific endpoint documentation. This API is designed to be flexible and easy to integrate into your applications.
